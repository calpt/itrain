dataset:
  dataset_name: hotpotqa
  max_seq_length: 384
  doc_stride: 256
model:
  model_name_or_path: roberta-base
  use_fast_tokenizer: true
  train_adapter: true
  adapter_config: pfeiffer
training:
  learning_rate: 0.0001
  batch_size: 8
  num_train_epochs: 15
  patience: 2
  patience_metric: eval_f1
evaluation: true
logging:
  wandb:
    project: itrain-experiments
restarts: 3
